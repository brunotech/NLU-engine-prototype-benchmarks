{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ipysheet\n",
    "from utils.nlu_engine import NLUEngine, LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data set cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and overview of data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    data_df = pd.read_csv(file_name, sep=';')\n",
    "    return data_df.dropna(axis=0, how='any', subset=['answer_annotation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu_data_df = load_data(\n",
    "    'NLU-Data-Home-Domain-Annotated-All.csv'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some issues with the answer_annotation not being similar to the answer_normalised. Therefore, we will make our own answer_normalised from the answer_annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu_data_df = NLUEngine.convert_annotated_utterances_to_normalised_utterances(\n",
    "    nlu_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From a total of 25673 utterances, there are 18 domains, 54 intents and 25673 utterances.\n",
      "\n",
      "List of domains: ['alarm' 'audio' 'iot' 'calendar' 'play' 'general' 'datetime' 'takeaway'\n",
      " 'news' 'music' 'weather' 'qa' 'social' 'recommendation' 'cooking' 'email'\n",
      " 'transport' 'lists']\n",
      "\n",
      "List of intents: ['set' 'volume_mute' 'hue_lightchange' 'hue_lightoff' 'hue_lighton'\n",
      " 'hue_lightdim' 'cleaning' 'query' 'music' 'quirky' 'greet' 'convert'\n",
      " 'remove' 'likeness' 'hue_lightup' 'order' 'settings' 'volume_down' 'joke'\n",
      " 'dislikeness' 'volume_other' 'coffee' 'volume_up' 'wemo_on' 'wemo_off'\n",
      " 'stock' 'radio' 'post' 'locations' 'recipe' 'sendemail' 'factoid'\n",
      " 'events' 'audiobook' 'podcasts' 'ticket' 'movies' 'game' 'traffic'\n",
      " 'definition' 'querycontact' 'createoradd' 'addcontact' 'taxi' 'maths'\n",
      " 'currency' 'negate' 'dontcare' 'repeat' 'affirm' 'commandstop' 'confirm'\n",
      " 'explain' 'praise']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "number_of_domains = len(nlu_data_df['scenario'].unique())\n",
    "list_of_domains = nlu_data_df['scenario'].unique()\n",
    "\n",
    "number_of_intents = nlu_data_df['intent'].nunique()\n",
    "list_of_intents = nlu_data_df['intent'].unique()\n",
    "\n",
    "number_of_utterances = nlu_data_df['answer_normalised'].nunique()\n",
    "\n",
    "print(f'From a total of {number_of_utterances} utterances, there are {number_of_domains} domains, {number_of_intents} intents and {number_of_utterances} utterances.\\n')\n",
    "\n",
    "print(f'List of domains: {list_of_domains}\\n')\n",
    "\n",
    "print(f'List of intents: {list_of_intents}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intent classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the intents and the domains (scenarios/skills) can be used to label an utterance. In this example we will use domains to label the utterances' intents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LogisticRegression(random_state=0, solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "domains = nlu_data_df.scenario.values\n",
    "\n",
    "LR_domain_classifier_model, tfidf_vectorizer = NLUEngine.train_intent_classifier(\n",
    "    data_df_path=nlu_data_df,\n",
    "    labels_to_predict='domain',\n",
    "    classifier=LR\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Let's try to predict an utterances intent label using the domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting label for utterance: turn off the kitchen lights\n",
      "iot\n"
     ]
    }
   ],
   "source": [
    "utterance = \"turn off the kitchen lights\"\n",
    "\n",
    "print(NLUEngine.predict_label(\n",
    "    LR_domain_classifier_model, tfidf_vectorizer, utterance))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create intent classifier report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LogisticRegression(random_state=0, solver='liblinear')\n",
      "Cross validating with LogisticRegression(random_state=0, solver='liblinear')\n",
      "Time it took to cross validate LogisticRegression(random_state=0, solver='liblinear'): 4.581929445266724\n",
      "Generating report for LogisticRegression(random_state=0, solver='liblinear')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bartmoss/code/NLU-engine-prototype-benchmarks/utils/nlu_engine/analytics.py:44: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier'] = df['classifier'].str.replace(r\"\\([^()]*\\)\", \"\")\n"
     ]
    }
   ],
   "source": [
    "domain_labels = 'scenario'\n",
    "\n",
    "domain_report_df = NLUEngine.evaluate_intent_classifier(\n",
    "    data_df_path=nlu_data_df,\n",
    "    labels_to_predict=domain_labels,\n",
    "    classifier=LR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>classifier</th>\n",
       "      <th>encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alarm</td>\n",
       "      <td>0.987455</td>\n",
       "      <td>0.884430</td>\n",
       "      <td>0.933108</td>\n",
       "      <td>623.000000</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio</td>\n",
       "      <td>0.938080</td>\n",
       "      <td>0.735437</td>\n",
       "      <td>0.824490</td>\n",
       "      <td>412.000000</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>calendar</td>\n",
       "      <td>0.841411</td>\n",
       "      <td>0.918620</td>\n",
       "      <td>0.878322</td>\n",
       "      <td>2986.000000</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cooking</td>\n",
       "      <td>0.929530</td>\n",
       "      <td>0.657957</td>\n",
       "      <td>0.770515</td>\n",
       "      <td>421.000000</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datetime</td>\n",
       "      <td>0.846834</td>\n",
       "      <td>0.795297</td>\n",
       "      <td>0.820257</td>\n",
       "      <td>723.000000</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>email</td>\n",
       "      <td>0.944970</td>\n",
       "      <td>0.905329</td>\n",
       "      <td>0.924725</td>\n",
       "      <td>1764.000000</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>general</td>\n",
       "      <td>0.807183</td>\n",
       "      <td>0.828745</td>\n",
       "      <td>0.817822</td>\n",
       "      <td>6102.000000</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iot</td>\n",
       "      <td>0.964623</td>\n",
       "      <td>0.924642</td>\n",
       "      <td>0.944209</td>\n",
       "      <td>1327.000000</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lists</td>\n",
       "      <td>0.923243</td>\n",
       "      <td>0.860020</td>\n",
       "      <td>0.890511</td>\n",
       "      <td>993.000000</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>music</td>\n",
       "      <td>0.897375</td>\n",
       "      <td>0.642735</td>\n",
       "      <td>0.749004</td>\n",
       "      <td>585.000000</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>news</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.735462</td>\n",
       "      <td>0.792870</td>\n",
       "      <td>877.000000</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>play</td>\n",
       "      <td>0.879221</td>\n",
       "      <td>0.846919</td>\n",
       "      <td>0.862768</td>\n",
       "      <td>2613.000000</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>qa</td>\n",
       "      <td>0.641065</td>\n",
       "      <td>0.883966</td>\n",
       "      <td>0.743171</td>\n",
       "      <td>2370.000000</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>recommendation</td>\n",
       "      <td>0.822414</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.749411</td>\n",
       "      <td>693.000000</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>social</td>\n",
       "      <td>0.959253</td>\n",
       "      <td>0.777166</td>\n",
       "      <td>0.858663</td>\n",
       "      <td>727.000000</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>takeaway</td>\n",
       "      <td>0.933526</td>\n",
       "      <td>0.780193</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>414.000000</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>transport</td>\n",
       "      <td>0.936192</td>\n",
       "      <td>0.874878</td>\n",
       "      <td>0.904497</td>\n",
       "      <td>1023.000000</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>weather</td>\n",
       "      <td>0.912745</td>\n",
       "      <td>0.876648</td>\n",
       "      <td>0.894332</td>\n",
       "      <td>1062.000000</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.844021</td>\n",
       "      <td>0.844021</td>\n",
       "      <td>0.844021</td>\n",
       "      <td>0.844021</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.890284</td>\n",
       "      <td>0.812042</td>\n",
       "      <td>0.844926</td>\n",
       "      <td>25715.000000</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.854897</td>\n",
       "      <td>0.844021</td>\n",
       "      <td>0.845411</td>\n",
       "      <td>25715.000000</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>tfidf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            domain  precision    recall  f1-score       support  \\\n",
       "0            alarm   0.987455  0.884430  0.933108    623.000000   \n",
       "1            audio   0.938080  0.735437  0.824490    412.000000   \n",
       "2         calendar   0.841411  0.918620  0.878322   2986.000000   \n",
       "3          cooking   0.929530  0.657957  0.770515    421.000000   \n",
       "4         datetime   0.846834  0.795297  0.820257    723.000000   \n",
       "5            email   0.944970  0.905329  0.924725   1764.000000   \n",
       "6          general   0.807183  0.828745  0.817822   6102.000000   \n",
       "7              iot   0.964623  0.924642  0.944209   1327.000000   \n",
       "8            lists   0.923243  0.860020  0.890511    993.000000   \n",
       "9            music   0.897375  0.642735  0.749004    585.000000   \n",
       "10            news   0.860000  0.735462  0.792870    877.000000   \n",
       "11            play   0.879221  0.846919  0.862768   2613.000000   \n",
       "12              qa   0.641065  0.883966  0.743171   2370.000000   \n",
       "13  recommendation   0.822414  0.688312  0.749411    693.000000   \n",
       "14          social   0.959253  0.777166  0.858663    727.000000   \n",
       "15        takeaway   0.933526  0.780193  0.850000    414.000000   \n",
       "16       transport   0.936192  0.874878  0.904497   1023.000000   \n",
       "17         weather   0.912745  0.876648  0.894332   1062.000000   \n",
       "18        accuracy   0.844021  0.844021  0.844021      0.844021   \n",
       "19       macro avg   0.890284  0.812042  0.844926  25715.000000   \n",
       "20    weighted avg   0.854897  0.844021  0.845411  25715.000000   \n",
       "\n",
       "            classifier encoding  \n",
       "0   LogisticRegression    tfidf  \n",
       "1   LogisticRegression    tfidf  \n",
       "2   LogisticRegression    tfidf  \n",
       "3   LogisticRegression    tfidf  \n",
       "4   LogisticRegression    tfidf  \n",
       "5   LogisticRegression    tfidf  \n",
       "6   LogisticRegression    tfidf  \n",
       "7   LogisticRegression    tfidf  \n",
       "8   LogisticRegression    tfidf  \n",
       "9   LogisticRegression    tfidf  \n",
       "10  LogisticRegression    tfidf  \n",
       "11  LogisticRegression    tfidf  \n",
       "12  LogisticRegression    tfidf  \n",
       "13  LogisticRegression    tfidf  \n",
       "14  LogisticRegression    tfidf  \n",
       "15  LogisticRegression    tfidf  \n",
       "16  LogisticRegression    tfidf  \n",
       "17  LogisticRegression    tfidf  \n",
       "18  LogisticRegression    tfidf  \n",
       "19  LogisticRegression    tfidf  \n",
       "20  LogisticRegression    tfidf  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.nlu_engine import EntityExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to have the NLTK tokenizer to be able to extract entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "        nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training entity classifier\n"
     ]
    }
   ],
   "source": [
    "crf_model = NLUEngine.train_entity_classifier(data_df=nlu_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Let's try an example utterance for entity extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterance = 'wake me up at five pm this week'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the entity tags of a specific utterance with the EntityExtractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('time', 'five'), ('time', 'pm'), ('date', 'this'), ('date', 'week')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EntityExtractor.get_entity_tags(utterance, crf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the entity tagged utterance with the NLUEngine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wake me up at [time : five pm] [date : this week]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_tagged_utterance = NLUEngine.create_entity_tagged_utterance(\n",
    "    utterance, crf_model)\n",
    "\n",
    "entity_tagged_utterance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity extraction report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to this error featured in [this git issue](https://github.com/TeamHG-Memex/sklearn-crfsuite/issues/60) we have to use an older version of scikit learn (sklearn<0.24), otherwise the latest version would work. Hopefully this gets fixed one day.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating entity classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bartmoss/code/NLU-engine-prototype-benchmarks/.venv/lib/python3.7/site-packages/sklearn/base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating with CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
      "    keep_tempfiles=None, max_iterations=100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/bartmoss/code/NLU-engine-prototype-benchmarks/.venv/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it took to cross validate CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
      "    keep_tempfiles=None, max_iterations=100): 452.1003019809723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bartmoss/code/NLU-engine-prototype-benchmarks/.venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity-type</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.879848</td>\n",
       "      <td>0.952758</td>\n",
       "      <td>0.914852</td>\n",
       "      <td>73769.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alarm_type</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>app_name</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.460526</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>artist_name</td>\n",
       "      <td>0.496656</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.476726</td>\n",
       "      <td>648.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audiobook_author</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>audiobook_name</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>301.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>business_name</td>\n",
       "      <td>0.372385</td>\n",
       "      <td>0.186192</td>\n",
       "      <td>0.248257</td>\n",
       "      <td>956.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>business_type</td>\n",
       "      <td>0.708920</td>\n",
       "      <td>0.404826</td>\n",
       "      <td>0.515358</td>\n",
       "      <td>373.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>change_amount</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.197605</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>167.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>coffee_type</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>color_type</td>\n",
       "      <td>0.805085</td>\n",
       "      <td>0.533708</td>\n",
       "      <td>0.641892</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cooking_type</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>currency_name</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>894.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>date</td>\n",
       "      <td>0.875621</td>\n",
       "      <td>0.886533</td>\n",
       "      <td>0.881043</td>\n",
       "      <td>4574.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>definition_word</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>558.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>device_type</td>\n",
       "      <td>0.789349</td>\n",
       "      <td>0.809466</td>\n",
       "      <td>0.799281</td>\n",
       "      <td>824.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>drink_type</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>email_address</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.839506</td>\n",
       "      <td>170.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>email_folder</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.953271</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>event_name</td>\n",
       "      <td>0.559722</td>\n",
       "      <td>0.606471</td>\n",
       "      <td>0.582160</td>\n",
       "      <td>2658.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>food_type</td>\n",
       "      <td>0.557957</td>\n",
       "      <td>0.373684</td>\n",
       "      <td>0.447597</td>\n",
       "      <td>760.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>game_name</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>331.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>game_type</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>general_frequency</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.516605</td>\n",
       "      <td>0.589474</td>\n",
       "      <td>271.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>house_place</td>\n",
       "      <td>0.888594</td>\n",
       "      <td>0.773672</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>433.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ingredient</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>joke_type</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>list_name</td>\n",
       "      <td>0.065041</td>\n",
       "      <td>0.013559</td>\n",
       "      <td>0.022440</td>\n",
       "      <td>590.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>meal_type</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.707965</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>113.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>media_type</td>\n",
       "      <td>0.727064</td>\n",
       "      <td>0.308366</td>\n",
       "      <td>0.433060</td>\n",
       "      <td>1028.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>movie_name</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>movie_type</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>music_album</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>music_descriptor</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.080537</td>\n",
       "      <td>0.112676</td>\n",
       "      <td>149.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>music_genre</td>\n",
       "      <td>0.733668</td>\n",
       "      <td>0.717445</td>\n",
       "      <td>0.725466</td>\n",
       "      <td>407.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>news_topic</td>\n",
       "      <td>0.075269</td>\n",
       "      <td>0.170992</td>\n",
       "      <td>0.104526</td>\n",
       "      <td>655.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>order_type</td>\n",
       "      <td>0.830882</td>\n",
       "      <td>0.545894</td>\n",
       "      <td>0.658892</td>\n",
       "      <td>207.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>person</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.498507</td>\n",
       "      <td>0.566102</td>\n",
       "      <td>2010.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>personal_info</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.443038</td>\n",
       "      <td>0.505415</td>\n",
       "      <td>158.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>place_name</td>\n",
       "      <td>0.658882</td>\n",
       "      <td>0.652868</td>\n",
       "      <td>0.655861</td>\n",
       "      <td>3068.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>player_setting</td>\n",
       "      <td>0.514563</td>\n",
       "      <td>0.150997</td>\n",
       "      <td>0.233480</td>\n",
       "      <td>351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>playlist_name</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.256881</td>\n",
       "      <td>0.321839</td>\n",
       "      <td>218.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>podcast_descriptor</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>277.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>podcast_name</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>207.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>query_detail</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>radio_name</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>966.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>relation</td>\n",
       "      <td>0.788770</td>\n",
       "      <td>0.648352</td>\n",
       "      <td>0.711701</td>\n",
       "      <td>455.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>song_name</td>\n",
       "      <td>0.157525</td>\n",
       "      <td>0.185738</td>\n",
       "      <td>0.170472</td>\n",
       "      <td>603.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>sport_type</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>time</td>\n",
       "      <td>0.787005</td>\n",
       "      <td>0.826290</td>\n",
       "      <td>0.806169</td>\n",
       "      <td>3005.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>time_zone</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.291339</td>\n",
       "      <td>0.408840</td>\n",
       "      <td>127.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>timeofday</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.930288</td>\n",
       "      <td>0.893764</td>\n",
       "      <td>416.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>transport_agency</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.144578</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>transport_descriptor</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>transport_name</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>transport_type</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>0.028369</td>\n",
       "      <td>548.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>weather_descriptor</td>\n",
       "      <td>0.812121</td>\n",
       "      <td>0.534574</td>\n",
       "      <td>0.644747</td>\n",
       "      <td>752.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.822414</td>\n",
       "      <td>0.822414</td>\n",
       "      <td>0.822414</td>\n",
       "      <td>0.822414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.419676</td>\n",
       "      <td>0.309187</td>\n",
       "      <td>0.339111</td>\n",
       "      <td>104873.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.790687</td>\n",
       "      <td>0.822414</td>\n",
       "      <td>0.801014</td>\n",
       "      <td>104873.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             entity-type  precision    recall  f1-score        support\n",
       "0                      0   0.879848  0.952758  0.914852   73769.000000\n",
       "1             alarm_type   0.000000  0.000000  0.000000      30.000000\n",
       "2               app_name   0.700000  0.460526  0.555556      76.000000\n",
       "3            artist_name   0.496656  0.458333  0.476726     648.000000\n",
       "4       audiobook_author   0.000000  0.000000  0.000000      31.000000\n",
       "5         audiobook_name   0.000000  0.000000  0.000000     301.000000\n",
       "6          business_name   0.372385  0.186192  0.248257     956.000000\n",
       "7          business_type   0.708920  0.404826  0.515358     373.000000\n",
       "8          change_amount   0.500000  0.197605  0.283262     167.000000\n",
       "9            coffee_type   1.000000  0.140000  0.245614      50.000000\n",
       "10            color_type   0.805085  0.533708  0.641892     178.000000\n",
       "11          cooking_type   0.000000  0.000000  0.000000      27.000000\n",
       "12         currency_name   0.031250  0.001119  0.002160     894.000000\n",
       "13                  date   0.875621  0.886533  0.881043    4574.000000\n",
       "14       definition_word   0.000000  0.000000  0.000000     558.000000\n",
       "15           device_type   0.789349  0.809466  0.799281     824.000000\n",
       "16            drink_type   0.000000  0.000000  0.000000      23.000000\n",
       "17         email_address   0.883117  0.800000  0.839506     170.000000\n",
       "18          email_folder   0.980769  0.927273  0.953271      55.000000\n",
       "19            event_name   0.559722  0.606471  0.582160    2658.000000\n",
       "20             food_type   0.557957  0.373684  0.447597     760.000000\n",
       "21             game_name   0.000000  0.000000  0.000000     331.000000\n",
       "22             game_type   0.000000  0.000000  0.000000       3.000000\n",
       "23     general_frequency   0.686275  0.516605  0.589474     271.000000\n",
       "24           house_place   0.888594  0.773672  0.827160     433.000000\n",
       "25            ingredient   0.000000  0.000000  0.000000      52.000000\n",
       "26             joke_type   0.888889  0.533333  0.666667      75.000000\n",
       "27             list_name   0.065041  0.013559  0.022440     590.000000\n",
       "28             meal_type   0.714286  0.707965  0.711111     113.000000\n",
       "29            media_type   0.727064  0.308366  0.433060    1028.000000\n",
       "30            movie_name   0.000000  0.000000  0.000000      54.000000\n",
       "31            movie_type   0.000000  0.000000  0.000000      24.000000\n",
       "32           music_album   0.000000  0.000000  0.000000       8.000000\n",
       "33      music_descriptor   0.187500  0.080537  0.112676     149.000000\n",
       "34           music_genre   0.733668  0.717445  0.725466     407.000000\n",
       "35            news_topic   0.075269  0.170992  0.104526     655.000000\n",
       "36            order_type   0.830882  0.545894  0.658892     207.000000\n",
       "37                person   0.654902  0.498507  0.566102    2010.000000\n",
       "38         personal_info   0.588235  0.443038  0.505415     158.000000\n",
       "39            place_name   0.658882  0.652868  0.655861    3068.000000\n",
       "40        player_setting   0.514563  0.150997  0.233480     351.000000\n",
       "41         playlist_name   0.430769  0.256881  0.321839     218.000000\n",
       "42    podcast_descriptor   0.000000  0.000000  0.000000     277.000000\n",
       "43          podcast_name   0.000000  0.000000  0.000000     207.000000\n",
       "44          query_detail   0.000000  0.000000  0.000000       8.000000\n",
       "45            radio_name   0.000000  0.000000  0.000000     966.000000\n",
       "46              relation   0.788770  0.648352  0.711701     455.000000\n",
       "47             song_name   0.157525  0.185738  0.170472     603.000000\n",
       "48            sport_type   0.000000  0.000000  0.000000      17.000000\n",
       "49                  time   0.787005  0.826290  0.806169    3005.000000\n",
       "50             time_zone   0.685185  0.291339  0.408840     127.000000\n",
       "51             timeofday   0.860000  0.930288  0.893764     416.000000\n",
       "52      transport_agency   0.545455  0.083333  0.144578      72.000000\n",
       "53  transport_descriptor   0.000000  0.000000  0.000000      35.000000\n",
       "54        transport_name   0.000000  0.000000  0.000000      58.000000\n",
       "55        transport_type   0.500000  0.014599  0.028369     548.000000\n",
       "56    weather_descriptor   0.812121  0.534574  0.644747     752.000000\n",
       "57              accuracy   0.822414  0.822414  0.822414       0.822414\n",
       "58             macro avg   0.419676  0.309187  0.339111  104873.000000\n",
       "59          weighted avg   0.790687  0.822414  0.801014  104873.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_report_df = NLUEngine.evaluate_entity_classifier(data_df=nlu_data_df)\n",
    "entity_report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the dataset\n",
    "Now that we know what works and what doesn't, we can clean the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't want all of the columns, so we will drop some to review the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu_scenario_data_df = nlu_data_df.drop(\n",
    "    columns=[\n",
    "        'userid', 'notes', 'answer', 'answer_normalised', 'answerid'\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a domain (scenario) to review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu_scenario_df = nlu_scenario_data_df[\n",
    "    nlu_scenario_data_df['scenario'] == 'iot'\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to ipysheet and review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall make two buttons. \n",
    "* **review**: Either changes have been made or the entry should be further reviewed\n",
    "* **remove**: We will drop the entry from the data set.\n",
    "\n",
    "Look at each utterance, check the following:\n",
    "* Is the utterance grammatically correct (and spelled correctly)?\n",
    "* Is the utterance in the correct language?\n",
    "* Is the utterance in the correct domain?\n",
    "* Is the utterance in the correct format?\n",
    "* Does the utterance actually make sense? (i.e. does it make sense to say it?)\n",
    "\n",
    "If you are unsure, you are marking your changes as **review** anyway, so that's cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu_scenario_df = nlu_scenario_df.assign(review=None)\n",
    "nlu_scenario_df['review'] = nlu_scenario_df['review'].astype(bool)\n",
    "\n",
    "nlu_scenario_df = nlu_scenario_df.assign(remove=None)\n",
    "nlu_scenario_df['remove'] = nlu_scenario_df['remove'].astype(bool)\n",
    "\n",
    "nlu_scenario_df_sheet = ipysheet.from_dataframe(nlu_scenario_df)\n",
    "nlu_scenario_sheet = ipysheet.from_dataframe(nlu_scenario_df)\n",
    "nlu_scenario_sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you are done reviewing, you convert it back to a dataframe and check to make sure it looks okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviwed_scenario_df = ipysheet.to_dataframe(nlu_scenario_sheet)\n",
    "reviwed_scenario_df.index = pd.to_numeric(reviwed_scenario_df.index)\n",
    "reviwed_scenario_df.tail(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are sure it is okay, you can save it as a csv file, make sure to name it correctly (i.e. `alarm_domain_first_review.csv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviwed_scenario_df.to_csv('iot_domain_first_review.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load it back up and check to make sure it looks okay. Make sure to give it the right name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_domain_first_review_df = pd.read_csv(\n",
    "    'iot_domain_first_review.csv', index_col=0)\n",
    "audio_domain_first_review_df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement the evaluate_classifier in the NLU engine to check f1 score for intents and entities in the domain vs original NLU data of domain!\n",
    "# Value: benchmark!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: cancat all reviewed dfs and save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add benchmark for whole NLU data set before and after cleaning! (by intents and domains!)\n",
    "# TODO: review the review marked entries\n",
    "# TODO: add new column for notes\n",
    "# TODO: change flow of review for only ones that should be reviewed, not all of the ones that have been changed (track changes by comparing against the original data set)\n",
    "# TODO: do the changed utterances have to be changed in other fields too or is it just enough for the tagged utterancve field?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add visualizations of domains, their intents, keywords in utterances, and entities"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f1ecf1ecc6a840da86e8b827c66035ad900dc97d6a10e234826dd106c37257af"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
